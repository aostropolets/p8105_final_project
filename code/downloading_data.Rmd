---
title: "downloading_data"
output: github_document
---

```{r}
library(readxl)
library(rvest)
library(stringr)
library(tidyverse)
library(filesstrings)
```

Creating list of date codes and URLs for the current data file and all archived files.

Dates and URLs came from inspecting this website:
https://www.srtr.org/reports/program-specific-reports/


```{r get_dates}

# archive date format is YYMM, two reports per year
# current year is available with kidney only data, but other years are in .zip

# there was a change in how regions were assigned in 2017

archive_dates_17 = c("1711", "1808", "1811", "1905", "1911", "2006")

# archive_dates = c("1207", "1301", "1307", "1401", "1406", "1412", "1506", "1512", "1606", "1701", "1707", "1711", "1808", "1811", "1905", "1911", "2006")

current_file_date = "2105"

current_file_url = "https://www.srtr.org/assets/media/PSRdownloads/csrs_tables/csrs_final_tables_2105_KI.xls"

url_base = "https://www.srtr.org/assets/media/PSRdownloads/csrs_tables_all/csrs_final_tables_"

# replace with archive_dates to get all years
vec_urls = str_c(url_base, archive_dates_17, "all.zip")

vec_dates = list(
  date = archive_dates_17,
  url = vec_urls
)
```

Download the most recent data and save it to /data folder:

```{r download_data}

current_file_path = "../data/csrs_final_tables_2105_KI.xls"

download.file(current_file_url, current_file_path, mode = "wb")

# Table B6 - SFL (survival from listing) is a unique table for the recent data
# Removed from analysis because it cannot readily be compared over time

# remove the second unnecessary descriptor line from each excel file

clean_sheets = function(fpath, x) {
  clean_sheet = readxl::read_xls(fpath, sheet = x)[-1,] %>%
    janitor::clean_names() %>%
    
    mutate(ctr_id = ifelse(
      "ctr_cd" %in% colnames(.), ctr_cd, center)) %>%
      #paste(CTR_CD, CTR_TY, sep = ""), 
      #center)) %>%
    select(ctr_id, everything())
  
  
  extract(d1, date_created, c('month', 'day', 'year'),
              '([^-]+)-([^-]+)-([^-]+)', remove=FALSE)
  
  return(clean_sheet)
}

current_data = sapply(readxl::excel_sheets(current_file_path), 
                      simplify = F, 
                      USE.NAMES = T, 
                      function (X) clean_sheets(current_file_path, X)) %>%
  within(rm("Table B6 - SFL"))

current_data[[1]]

```

Function to download archived files:

```{r download_archives}

download_archived_data = function(url) {
  
  # to save to temp folder instead of download, use temp
  temp = tempfile()
  
  download.file(url, temp, mode = "wb")
  
  ki_file = tibble(files = as.character(unzip(temp, list = TRUE)$Name)) %>% 
    filter(str_detect(files, "KI\\.[xX][lL][sS]$"))
  
  ki_filepath = ki_file[[1]]
  
  ki_data = sapply(readxl::excel_sheets(unzip(temp, ki_filepath)), 
                    simplify = F, USE.NAMES = T,
            function(X) clean_sheets(unzip(temp, ki_filepath), X))
  
  
  unlink(temp)
  move_files(ki_filepath, "../data/")
  
  return(ki_data)
}
```

Compiling all data files (archived and current) into one nested list:

```{r combine_data}

data_all_yrs = map(.x = vec_dates$url, ~download_archived_data(url = .x))

data_all_yrs = append(data_all_yrs, list(current_data))

name_labels = vec_dates$date %>% 
  append(current_file_date)

names(data_all_yrs) = str_c("data_", name_labels)

```

``` {r}

subset_test = current_data[c(1,4,5,length(current_data))]

#map(.x = subset_test[everything])

new_df = last(subset_test)

for (i in length(subset_test)) {
   merge(new_df, subset_test[[i]], all = TRUE, suffixes = paste("sheet_",i), suffixes = paste("sheet",i))
}

subset_test
```
Now check to see if the column names are the same across sheets and years

```{r}

# for each sheet in each file
# need to first remove the 1st row after the titles
# check the first column name
# if center -> change name to CTR_CD and CTR_TY


for (i in 1:length(data_all_yrs)) {
  
  data_all_yrs[[i]][["Tiers"]]
  
  add_id_cols = c("Tbls B4-B5 & Fig B1-B6 - All", 
                  "Tbls B4-B5 & Fig B1-B6 - Adult", 
                  "Tbls B4-B5 & Fig B1-B6 - Peds" )
  
  for (sheet_name in add_id_cols) {
    
    data_all_yrs[[i]][[sheet_name]] = data_all_yrs[[i]][[sheet_name]] %>%
       mutate(
         "CTR_CD"= str_split(string = center,
                                        pattern = "[A-Z]{4}",
                                        n =2)[1],
         "CTR_TY" = str_split(string = center,
                                        pattern = "[A-Z]{4}",
                                        n =2)[2])
    }

  #data_all_yrs[[i]][["Tiers"]])
  
  # if str_match(name, "^Tbl") %>%
  #   mutate(
  #     CTR_CD = str_split(string = center, pattern = "[A-Z]{4}", n = 2)
  #   )
  # print(names(data_all_yrs[[i]]))
    
}


data_all_yrs[[i]][["Tbls B4-B5 & Fig B1-B6 - All"]]$CTR_CD

  print(names(data_all_yrs[[i]]))
  # sheet_names_list[[i]] = as_tibble(data_all_yrs[[i]] %>% names) %>%
  #   rename_with(~ paste("sheet_name")) %>%
  #   mutate("sheet_num" = 1:n()) %>%
  #   pivot_wider(
  #     names_from = sheet_num, 
  #     names_prefix = "sheet_", 
  #     values_from = sheet_name)
  # names(sheet_names_list) = names(data_all_yrs)

}
```

```{r check_cols_match}

# combine the wait list info (Sheet Table 1 or B1) across years
# first make sure the columns match - sheet names changed in 2014 and 11/2017

col_names_list = list()
sheet_names_list = list()

for (i in 1:length(data_all_yrs)) {
  
  sheet_names_list[[i]] = as_tibble(data_all_yrs[[i]] %>% names) %>%
    rename_with(~ paste("sheet_name")) %>%
    mutate("sheet_num" = 1:n()) %>%
    pivot_wider(
      names_from = sheet_num, 
      names_prefix = "sheet_", 
      values_from = sheet_name)
  names(sheet_names_list) = names(data_all_yrs)
  
  # make sure that the sheets contain the same columns
  for (sheet_i in 1:length(data_all_yrs[[i]])) {
    col_names_list[[i]] = as_tibble(data_all_yrs[[i]][[sheet_i]] %>% names) %>%
    rename_with(~ paste("value_name")) %>%
    mutate(
      # name the first column for the old files to match the recent ones
      value_name = str_replace(value_name, pattern = "...1", replacement = "ENTIRE_NAME"), 
      "col_num" = 1:n()) %>%
    pivot_wider(names_from = col_num, 
                names_prefix = "col_", 
                values_from = value_name))
    
    names(col_names_list) = (as.character(sheet_i)data_all_yrs[[i]] %>% names)
    
    if (sheet_i == length(data_all_yrs[[i]])) {
      col_names_df = bind_rows(col_names_list)
    }
    
  }
  
  if (i == length(data_all_yrs)) {
    sheet_names_df = bind_rows(sheet_names_list)
    col_names_df = bind_rows(col_names_list)
  }
}

if ((col_names_df %>% unique() %>% nrow() != 1) | (sheet_names_df %>% unique() %>% nrow() != 1)) {
  stop("Column names and sheet names are not the same across sheets, check data again")
}

# make a quick dictionary of column names for table1/B1
col_def_list = as.list(slice(data_all_yrs[[1]][[1]], n = 1))
names(col_def_list) = (as.character(col_names_df[1,]))

# bind the rows together
#map(.x = data_all_yrs, grab_sheet_1)

col_names_df
sheet_names_df


as_tibble(t(sapply(data_all_yrs, c))[1,])
```
